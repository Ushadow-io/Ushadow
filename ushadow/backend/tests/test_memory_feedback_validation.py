"""
Test module for memory feedback validation logic.

Generated by automation-agent from test cases in:
specs/features/memory-feedback.testcases.md

Test Cases Covered:
- TC-MF-001: Validate Feedback Type
- TC-MF-002: Validate Corrected Text Length
- TC-MF-003: Sanitize Corrected Text for XSS
- TC-MF-004: Calculate Memory Status - Verified
- TC-MF-005: Calculate Memory Status - Disputed
- TC-MF-006: Calculate Memory Status - Corrected
"""

import pytest


# TC-MF-001: Validate Feedback Type
@pytest.mark.unit
@pytest.mark.no_secrets
def test_validate_feedback_type_valid_values():
    """
    Test Case: TC-MF-001 (Valid feedback types)

    Steps:
    1. Validate feedback_type="true"
    2. Validate feedback_type="false"
    3. Validate feedback_type="correction"

    Expected: All validations pass
    """
    from src.validators.memory_feedback import validate_feedback_type

    # Arrange & Act & Assert
    assert validate_feedback_type("true") is True
    assert validate_feedback_type("false") is True
    assert validate_feedback_type("correction") is True


@pytest.mark.unit
@pytest.mark.no_secrets
def test_validate_feedback_type_invalid_values():
    """
    Test Case: TC-MF-001 (Invalid feedback types)

    Steps:
    1. Validate feedback_type="invalid"
    2. Validate feedback_type=""
    3. Validate feedback_type=None

    Expected: All validations fail with appropriate error
    """
    from src.validators.memory_feedback import validate_feedback_type, ValidationError

    # Arrange
    invalid_types = ["invalid", "", None, "TRUE", "False", 123]

    # Act & Assert
    for invalid_type in invalid_types:
        with pytest.raises(ValidationError, match="feedback_type must be"):
            validate_feedback_type(invalid_type)


# TC-MF-002: Validate Corrected Text Length
@pytest.mark.unit
@pytest.mark.no_secrets
def test_validate_corrected_text_length():
    """
    Test Case: TC-MF-002

    Steps:
    1. Validate empty string
    2. Validate 1 character
    3. Validate 2000 characters
    4. Validate 2001 characters

    Expected: Only 1-2000 chars pass
    """
    from src.validators.memory_feedback import (
        validate_corrected_text,
        ValidationError,
    )

    # Empty/None should fail
    with pytest.raises(ValidationError, match="corrected_text is required"):
        validate_corrected_text("")

    with pytest.raises(ValidationError, match="corrected_text is required"):
        validate_corrected_text(None)

    # 1 char should pass
    assert validate_corrected_text("a") is True

    # 2000 chars should pass
    assert validate_corrected_text("x" * 2000) is True

    # 2001 chars should fail
    with pytest.raises(ValidationError, match="exceeds maximum length"):
        validate_corrected_text("x" * 2001)


# TC-MF-003: Sanitize Corrected Text for XSS
@pytest.mark.unit
@pytest.mark.no_secrets
def test_sanitize_corrected_text_xss_prevention():
    """
    Test Case: TC-MF-003

    Steps:
    1. Input malicious script tags
    2. Input image with onerror
    3. Input javascript: protocol
    4. Input normal text with HTML entities

    Expected: All malicious code escaped/stripped, safe text preserved
    """
    from src.utils.sanitize import sanitize_html

    # Malicious inputs
    assert "<script>" not in sanitize_html("<script>alert('xss')</script>")
    assert "onerror" not in sanitize_html("<img src=x onerror=alert('xss')>")
    assert "javascript:" not in sanitize_html("javascript:alert('xss')")

    # Safe HTML entities should be encoded
    result = sanitize_html('<p>Test & "quotes"</p>')
    assert "&lt;" in result or "<p>" not in result  # Tags escaped or stripped

    # Plain text preserved
    plain_text = "This is normal text without HTML"
    assert sanitize_html(plain_text) == plain_text


# TC-MF-004, TC-MF-005, TC-MF-006: Calculate Memory Status
@pytest.mark.unit
@pytest.mark.no_secrets
@pytest.mark.parametrize(
    "feedback_summary,expected_status",
    [
        # TC-MF-004: Verified (>= 3 true)
        ({"true": 3, "false": 0, "correction": 0}, "verified"),
        ({"true": 5, "false": 1, "correction": 0}, "verified"),
        # TC-MF-005: Disputed (>= 2 false)
        ({"true": 1, "false": 2, "correction": 0}, "disputed"),
        ({"true": 0, "false": 3, "correction": 0}, "disputed"),
        # TC-MF-006: Corrected (has corrections)
        ({"true": 1, "false": 0, "correction": 1}, "corrected"),
        ({"true": 2, "false": 1, "correction": 2}, "corrected"),
        # Edge case: Unverified (no significant feedback)
        ({"true": 1, "false": 0, "correction": 0}, "unverified"),
        ({"true": 2, "false": 1, "correction": 0}, "unverified"),
    ],
)
def test_calculate_memory_status(feedback_summary, expected_status):
    """
    Test Cases: TC-MF-004, TC-MF-005, TC-MF-006

    Verifies memory status calculation based on feedback counts.

    Rules:
    - >= 3 true feedbacks → "verified"
    - >= 2 false feedbacks → "disputed"
    - > 0 corrections → "corrected"
    - Otherwise → "unverified"
    """
    from src.models.memory import calculate_memory_status

    # Act
    status = calculate_memory_status(feedback_summary)

    # Assert
    assert status == expected_status
